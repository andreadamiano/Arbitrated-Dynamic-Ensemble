\chapter{Methodology}

\section{Exploratory Data Analysis} 


\section{Data Preprocessing}
\cite{Daniel2019}


\subsection{Handling Non-Stationarity} % Content for handling non-stationarity

Augmented Dickey-Fuller (ADF) test





\subsection{Feature Engineering and Temporal Feature Extraction} % Content for feature engineering
\subsection{Label selection}
Labelling can have a major influence on a model training
to Financial Time Series. Some labels can also results in
non-tradable strategies. For instance, predicting a technical indicator created from lagged prices can be not usable for real trading, even when getting very accurate predictions.


\section{Choice of Base Models}
\subsection{Statistical models}
\subsection{Tree ensembles}
\subsection{Deep leanring models}


\section{Multi-Step Forecasting}


\section{Residual Ensembling Approach}
%Steps for sequentially modeling linear and nonlinear patterns
%Details on calculating residuals and using them in machine learning models


\section{Arbitrated Dynamic Ensemble (ADE)}
\subsection{Overview} %Introduction to Arbitrated Dynamic Ensemble, a method for dynamically adjusting model weights based on recent data patterns.
\subsection{Dynamic Weighting Mechanisms} %Explanation of how ADE dynamically weights model contributions, allowing the ensemble to adapt to evolving patterns in the data.
\subsection{Role of the Meta-Learner} %Description of the meta-learner’s role in assessing model performance and optimizing ensemble weighting for improved forecast accuracy.


\section{Proposed Model Architecture} 
\subsection{Hybrid Model Composition} %Explanation of the architecture that integrates ARIMA, tree ensembles (e.g., XGBoost), and deep learning models for a comprehensive solution to model both linear and nonlinear dependencies.
\subsection{Workflow} %Step-by-step outline of the complete modeling pipeline, including training, ensembling, and applying ADE adjustments.
%End-to-End Prediction Pipeline: Summary of the end-to-end process from data preprocessing to final predictions, detailing each model’s role and the integration with ADE.


\section{Evaluation Metrics for Model Performance}
\subsection{Root Mean Square Error (RMSE)} %Selection of RMSE for its ability to penalize larger errors, particularly relevant for time series forecasting.
\subsection{Mean Absolute Error (MAE)} %Justification for using MAE to provide an overall measure of prediction accuracy based on absolute differences.


